Exercise 1. What, in your own words, is “artificial intelligence”?
<details>
  answer here
</details>
  
Exercise 2. What, in your own words, is “machine learning”?
    
<details> answer here </details>
  
Exercise 3. Describe an autoencoder? (Recall the two “pieces”)
  
<details> answer here </details>
  
Exercise 4. Give a real-world example of some “factors of variations”
  
<details> answer here </details>
  
Exercise 5. How does deep learning solve the central problem in representative learning?

<details> answer here </details>
  
Exercise 6. Describe what a MLP ( ) is

<details> answer here </details>

Exercise 7. Describe the difference between computational graphs and probabilistic modeling graphs. For instance, what is the difference in the meaning of “depth”?

<details> answer here </details>

Exercise 8. What is a ”linear model” in the context of machine learning? Why would the
perceptron and ADALINE both be classified as linear models?

<details> answer here </details>
  

Exercise 9. Give one reason why the brain is not as large of a factor in deep learning
research today

<details> answer here </details>
  

Exercise 10. What is the central idea of connectionism?

<details> answer here </details>
  
Exercise 11. What is a distributed representation?

<details> answer here </details>
  
Exercise 12. When was the BackProp algorithm first introduced?

<details> answer here </details>
  
Exercise 13. What is LSTM? (Just a brief description of the idea – we won’t see the details
until chapter 10)

<details> answer here </details>
  

Exercise 14. What is MNIST? Why did Hinton call MNIST ”the drosophila of machine
learning”?

<details> answer here </details>
  
Exercise 15. As a rough rule of thumb, how many labeled examples per category are
required for a supervised deep learning network to achieve acceptable performance? What
about for the network to achieve roughly human-level performance?

<details> answer here </details>
  
