Exercise 1. What, in your own words, is “artificial intelligence”?
<details>
  answer here
<\details>
  
Exercise 2. What, in your own words, is “machine learning”?
    
<details> answer here <\details>
  
Exercise 3. Describe an autoencoder? (Recall the two “pieces”)
  
<details> answer here <\details>
  
Exercise 4. Give a real-world example of some “factors of variations”
  
<details> answer here <\details>
  
Exercise 5. How does deep learning solve the central problem in representative learning?
Exercise 6. Describe what a MLP ( ) is
Exercise 7. Describe the difference between computational graphs and probabilistic modeling graphs. For instance, what is the difference in the meaning of “depth”?
Exercise 8. What is a ”linear model” in the context of machine learning? Why would the
perceptron and ADALINE both be classified as linear models?
Exercise 9. Give one reason why the brain is not as large of a factor in deep learning
research today
Exercise 10. What is the central idea of connectionism?
Exercise 11. What is a distributed representation?
Exercise 12. When was the BackProp algorithm first introduced?
Exercise 13. What is LSTM? (Just a brief description of the idea – we won’t see the details
until chapter 10)
Exercise 14. What is MNIST? Why did Hinton call MNIST ”the drosophila of machine
learning”?
Exercise 15. As a rough rule of thumb, how many labeled examples per category are
required for a supervised deep learning network to achieve acceptable performance? What
about for the network to achieve roughly human-level performance?
